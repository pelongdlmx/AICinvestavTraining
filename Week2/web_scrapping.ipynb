{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109cefbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --break-system-packages -r ./requirements.txt\n",
    "!python -m pip install --upgrade pip\n",
    "!apt-get update\n",
    "!apt-get install  libgl1\n",
    "!python3 -m spacy download en_core_web_sm --break-system-packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd6f3c8",
   "metadata": {},
   "source": [
    "# Web Scraping with Requests and BeautifulSoup\n",
    "\n",
    "+ In this section, we use Requests to download a Wikipedia page about Natural Language Processing, and BeautifulSoup to extract the raw text from <p> paragraph tags.\n",
    "\n",
    "This demonstrates how to:\n",
    "\n",
    "1. Send an HTTP request to a webpage\n",
    "\n",
    "2. Parse the HTML content\n",
    "\n",
    "3. Extract specific elements such as text paragraphs\n",
    "\n",
    "The extracted text will serve as our input for later NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17854c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\lib\\site-packages (4.13.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\lib\\site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\lib\\site-packages (from beautifulsoup4) (4.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: certifi in c:\\users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\lib\\site-packages (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install beautifulsoup4\n",
    "%pip install --upgrade certifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20dc0e45",
   "metadata": {},
   "outputs": [
    {
     "ename": "SSLError",
     "evalue": "HTTPSConnectionPool(host='en.wikipedia.org', port=443): Max retries exceeded with url: /wiki/Natural_language_processing (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1028)')))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSSLCertVerificationError\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\Lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\Lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\Lib\\site-packages\\urllib3\\connection.py:790\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m server_hostname_rm_dot = server_hostname.rstrip(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m sock_and_verified = \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname_rm_dot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[43m    \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    806\u001b[39m \u001b[43m    \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    807\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    808\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = sock_and_verified.socket\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\Lib\\site-packages\\urllib3\\connection.py:969\u001b[39m, in \u001b[36m_ssl_wrap_socket_and_match_hostname\u001b[39m\u001b[34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[39m\n\u001b[32m    967\u001b[39m         server_hostname = normalized\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m ssl_sock = \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\Lib\\site-packages\\urllib3\\util\\ssl_.py:480\u001b[39m, in \u001b[36mssl_wrap_socket\u001b[39m\u001b[34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[39m\n\u001b[32m    478\u001b[39m context.set_alpn_protocols(ALPN_PROTOCOLS)\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m ssl_sock = \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\Lib\\site-packages\\urllib3\\util\\ssl_.py:524\u001b[39m, in \u001b[36m_ssl_wrap_socket_impl\u001b[39m\u001b[34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[39m\n\u001b[32m    522\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\Lib\\ssl.py:455\u001b[39m, in \u001b[36mSSLContext.wrap_socket\u001b[39m\u001b[34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    450\u001b[39m                 do_handshake_on_connect=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    451\u001b[39m                 suppress_ragged_eofs=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    452\u001b[39m                 server_hostname=\u001b[38;5;28;01mNone\u001b[39;00m, session=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    453\u001b[39m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[32m    454\u001b[39m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msslsocket_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\Lib\\ssl.py:1076\u001b[39m, in \u001b[36mSSLSocket._create\u001b[39m\u001b[34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[39m\n\u001b[32m   1075\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1076\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\Lib\\ssl.py:1372\u001b[39m, in \u001b[36mSSLSocket.do_handshake\u001b[39m\u001b[34m(self, block)\u001b[39m\n\u001b[32m   1371\u001b[39m         \u001b[38;5;28mself\u001b[39m.settimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1372\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mSSLCertVerificationError\u001b[39m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1028)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mSSLError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\Lib\\site-packages\\urllib3\\connectionpool.py:488\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    487\u001b[39m         new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "\u001b[31mSSLError\u001b[39m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1028)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMaxRetryError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    518\u001b[39m     reason = error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    521\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mIncremented Retry for (url=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, url, new_retry)\n",
      "\u001b[31mMaxRetryError\u001b[39m: HTTPSConnectionPool(host='en.wikipedia.org', port=443): Max retries exceeded with url: /wiki/Natural_language_processing (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1028)')))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mSSLError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m url = \u001b[33m\"\u001b[39m\u001b[33mhttps://en.wikipedia.org/wiki/Natural_language_processing\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Send HTTP request\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Parse the HTML content using BeautifulSoup\u001b[39;00m\n\u001b[32m     11\u001b[39m soup = BeautifulSoup(response.content, \u001b[33m\"\u001b[39m\u001b[33mhtml.parser\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nxf33012\\.pyenv\\pyenv-win\\versions\\3.13.5\\Lib\\site-packages\\requests\\adapters.py:698\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    694\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ProxyError(e, request=request)\n\u001b[32m    696\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e.reason, _SSLError):\n\u001b[32m    697\u001b[39m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m    700\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n\u001b[32m    702\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mSSLError\u001b[39m: HTTPSConnectionPool(host='en.wikipedia.org', port=443): Max retries exceeded with url: /wiki/Natural_language_processing (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1028)')))"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Target URL (Wikipedia page on NLP)\n",
    "url = \"https://en.wikipedia.org/wiki/Natural_language_processing\"\n",
    "\n",
    "# Send HTTP request\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Extract the first few paragraph elements\n",
    "paragraphs = soup.find_all(\"p\") #p is the tag for paragraphs in HTML\n",
    "\n",
    "# Display the first 3 paragraphs\n",
    "for i, p in enumerate(paragraphs[:3]):\n",
    "    print(f\"Paragraph {i+1}:\\n\", p.get_text(strip=True), \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba83df3",
   "metadata": {},
   "source": [
    "Text Cleaning using SpaCy and NLTK\n",
    "==\n",
    "Now that we have raw HTML text, we clean it up and prepare it for NLP:\n",
    "\n",
    "1. Convert text to lowercase\n",
    "\n",
    "2. Remove stopwords (common words like “and”, “the”)\n",
    "\n",
    "3. Lemmatize the tokens (reduce words to their base form like “running” → “run”)\n",
    "\n",
    "We use:\n",
    "\n",
    "1. SpaCy for tokenization and lemmatization\n",
    "\n",
    "2. NLTK for stopwords in English\n",
    "\n",
    "This step transforms messy text into meaningful tokens suitable for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5831edd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the English SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Get raw text from the first paragraph\n",
    "text = paragraphs[0].get_text()\n",
    "\n",
    "# Process the text with SpaCy\n",
    "doc = nlp(text.lower())\n",
    "\n",
    "# Extract clean tokens: lemmatized, alphabetic, and not stopwords\n",
    "clean_tokens = [\n",
    "    token.lemma_ for token in doc\n",
    "    if token.is_alpha and token.text not in stopwords.words(\"english\")\n",
    "]\n",
    "\n",
    "# Show a preview of the result\n",
    "print(\"Cleaned tokens:\", clean_tokens[:20])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1ebb83",
   "metadata": {},
   "source": [
    "Spelling Correction with SymSpell\n",
    "==\n",
    "In real-world data, typos and spelling errors are common. SymSpell uses a precompiled dictionary with word frequencies and hash-based lookups to suggest corrections efficiently.\n",
    "\n",
    "Here we:\n",
    "\n",
    "1. Load a frequency dictionary\n",
    "\n",
    "2. Simulate a typo (\"langauge\")\n",
    "\n",
    "3. Retrieve correction suggestions like \"language\"\n",
    "\n",
    "SymSpell is extremely fast and accurate when working with large corpora (big collections of text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8703bbc-1961-4b4b-bce1-6a8098a30f4e",
   "metadata": {},
   "source": [
    "# Example using a simple dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1911f6c6-416e-414d-af10-4aef8544814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dictionary: list of (word, frequency) tuples\n",
    "dictionary = [\n",
    "    (\"apple\", 10),\n",
    "    (\"banana\", 5),\n",
    "    (\"orange\", 7),\n",
    "    (\"their\", 1),\n",
    "    (\"there\", 1),\n",
    "    (\"they're\", 1),\n",
    "    (\"receive\", 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79634b62-1726-4db8-87ce-086d1bd05d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from symspellpy import SymSpell\n",
    "\n",
    "# Initialize SymSpell with a maximum edit distance of 2\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2)\n",
    "\n",
    "# Add the dictionary\n",
    "for word, frequency in dictionary:\n",
    "    sym_spell.create_dictionary_entry(word, frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b4a933-3dc5-4563-a343-71475d6f097a",
   "metadata": {},
   "source": [
    "# Correct a Misspelled Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2ee94d-4d9f-4522-9ccd-742fa94effa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct a misspelled word\n",
    "misspelled_word = \"thier\"\n",
    "suggestions = sym_spell.lookup(misspelled_word, Verbosity.CLOSEST, max_edit_distance=2)\n",
    "\n",
    "print(f\"Misspelled: {misspelled_word}\")\n",
    "for suggestion in suggestions:\n",
    "        print(f\"Term: {suggestion.term}, Distance: {suggestion.distance}, Count: {suggestion.count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad128006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from symspellpy.symspellpy import SymSpell, Verbosity\n",
    "\n",
    "# File name and remote URL\n",
    "dictionary_path = \"frequency_dictionary_en_82_765.txt\"\n",
    "dictionary_url = \"https://raw.githubusercontent.com/mammothb/symspellpy/master/symspellpy/frequency_dictionary_en_82_765.txt\"\n",
    "\n",
    "# Download the file if it's not already present\n",
    "if not os.path.exists(dictionary_path):\n",
    "    print(\"Downloading SymSpell dictionary...\")\n",
    "    try:\n",
    "        urllib.request.urlretrieve(dictionary_url, dictionary_path)\n",
    "        print(\"Download complete.\")\n",
    "    except Exception as e:\n",
    "        print(\"Failed to download dictionary:\", e)\n",
    "\n",
    "# Initialize SymSpell search for spelling correction, max edit distance of 2 (insertions, deletions, substitutions, transpositions)\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2)\n",
    "\n",
    "# Load the dictionary file\n",
    "if os.path.exists(dictionary_path):\n",
    "    sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)     #for this dictionary, the term is in column 0 and the frequency is in column 1\n",
    "\n",
    "    # Test a misspelled word\n",
    "    misspelled_word = \"langauge\"\n",
    "    suggestions = sym_spell.lookup(misspelled_word, Verbosity.CLOSEST, max_edit_distance=2)\n",
    "\n",
    "    print(\"Suggestions for:\", misspelled_word)\n",
    "    for s in suggestions:\n",
    "        print(f\"- {s.term} (freq: {s.count})\")\n",
    "else:\n",
    "    print(\"Dictionary file not found. Cannot perform spell correction.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e0070f-abe9-4f1b-9931-fb608444fa97",
   "metadata": {},
   "source": [
    "# Misspelled Badly Segmented Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1953b75b-b864-4b8e-985b-9eb72cb90653",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_term = \"let'sbreakthissentenceintoindividualwords\"\n",
    "\n",
    "result = sym_spell.word_segmentation(input_term)\n",
    "\n",
    "print(f\"Segmented Sentence: {result.corrected_string}\")\n",
    "print(f\"Sum of Edit Distances: {result.distance_sum}\")\n",
    "print(f\"Sum of Log Probabilities: {result.log_prob_sum}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec212b2e",
   "metadata": {},
   "source": [
    "Entity Recognition with RegEx and FlashText\n",
    "==\n",
    "We now explore two techniques for extracting specific patterns or keywords:\n",
    "\n",
    "-RegEx (Regular Expressions): Great for structured patterns like emails, dates, prices.\n",
    "\n",
    "-FlashText: Optimized for fast keyword searches over long texts.\n",
    "\n",
    "We apply them to:\n",
    "\n",
    "-Find emails and dates in a string using regular expressions\n",
    "\n",
    "-Extract keywords using FlashText’s KeywordProcessor\n",
    "\n",
    "These tools are useful for lightweight NLP tasks like named entity spotting or tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab11b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from flashtext import KeywordProcessor\n",
    "\n",
    "# Sample sentence with email and date\n",
    "text_sample = \"Contact us at support@example.com or visit on 2024-12-30.\"\n",
    "\n",
    "# Extract email and date using RegEx\n",
    "emails = re.findall(r'\\b[\\w.-]+?@\\w+?\\.\\w+?\\b', text_sample)\n",
    "dates = re.findall(r'\\d{4}-\\d{2}-\\d{2}', text_sample)\n",
    "\n",
    "print(\"Emails found:\", emails)\n",
    "print(\"Dates found:\", dates)\n",
    "\n",
    "# Use FlashText to detect keywords\n",
    "keyword_processor = KeywordProcessor()\n",
    "keyword_processor.add_keywords_from_list([\"support\", \"visit\", \"example\"])\n",
    "\n",
    "matches = keyword_processor.extract_keywords(text_sample)\n",
    "print(\"FlashText matches:\", matches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92058f67",
   "metadata": {},
   "source": [
    "WordCloud Visualization\n",
    "==\n",
    "To summarize the cleaned text visually, we use WordCloud to display the most frequent terms.\n",
    "\n",
    "Steps:\n",
    "\n",
    "-Join the cleaned tokens into a single string\n",
    "\n",
    "-Generate a word cloud\n",
    "\n",
    "-Display it using matplotlib\n",
    "\n",
    "This is a quick and intuitive way to explore dominant topics in the scraped text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd3e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Join the cleaned tokens into a single string\n",
    "joined_text = \" \".join(clean_tokens)\n",
    "\n",
    "# Generate word cloud\n",
    "wordcloud = WordCloud(width=800, height=400).generate(joined_text)\n",
    "\n",
    "# Plot it\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"WordCloud from Scraped Text\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fecd568-4c0b-442e-b2d5-0aa5efbd5977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Sample text (replace this with your own text)\n",
    "text = \"\"\"\n",
    "Python is a programming language. Python is easy to learn.\n",
    "Python is used in data science, machine learning, and web development.\n",
    "Python has a vast ecosystem of libraries and tools.\n",
    "Python is loved by developers worldwide.\n",
    "Python is versatile and widely used in many industries.\n",
    "\"\"\"\n",
    "\n",
    "# Generate the word cloud\n",
    "wordcloud = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color='white',\n",
    "    colormap='viridis'  # You can change the color scheme\n",
    ").generate(text)\n",
    "\n",
    "# Display the word cloud using matplotlib\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")  # Hide the axes\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a364f8db",
   "metadata": {},
   "source": [
    "Practical Example- Web Scraping and Sentiment Analysis on News Articles\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f64323-9eb2-47bc-8b25-eef72b55c28d",
   "metadata": {},
   "source": [
    "### NLTK's VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool specifically designed for analyzing sentiment in social media texts and other short, informal text passages. It is part of the Natural Language Toolkit (NLTK) library in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dc7131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "News Sentiment Mini-Pipeline (Google News RSS + NLTK VADER)\n",
    "-----------------------------------------------------------\n",
    "- Input: a list of keywords (strings).\n",
    "- For each keyword, fetch the first N news items from Google News RSS.\n",
    "- Score sentiment using NLTK's VADER (title + summary).\n",
    "- Output: (1) DataFrame with per-article scores, (2) DataFrame with per-keyword summary.\n",
    "\n",
    "Good for teaching:\n",
    "- No API keys, minimal setup.\n",
    "- Transparent lexicon-based sentiment (VADER).\n",
    "- Easy to extend (CSV export, plots, etc.).\n",
    "\"\"\"\n",
    "\n",
    "from typing import List, Dict, Any\n",
    "import urllib.parse\n",
    "import feedparser\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "# ----------------------------- NLTK setup ------------------------------------\n",
    "def ensure_vader() -> None:\n",
    "    \"\"\"\n",
    "    Ensure the VADER lexicon is available. Download once if missing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nltk.data.find(\"sentiment/vader_lexicon.zip\")\n",
    "    except LookupError:\n",
    "        nltk.download(\"vader_lexicon\")\n",
    "\n",
    "\n",
    "# ------------------------- Google News RSS helpers ---------------------------\n",
    "def google_news_rss(query: str, hl: str = \"en-US\", gl: str = \"US\", ceid: str = \"US:en\") -> str:\n",
    "    \"\"\"\n",
    "    Build a Google News RSS URL for a given query.\n",
    "\n",
    "    Parameters:\n",
    "        query: search terms (e.g., \"bitcoin\" or \"artificial intelligence\").\n",
    "        hl: UI language (e.g., \"en-US\").\n",
    "        gl: geolocation (country code, e.g., \"US\").\n",
    "        ceid: country:language code used by Google News (e.g., \"US:en\").\n",
    "    \"\"\"\n",
    "    base = \"https://news.google.com/rss/search\"\n",
    "    q = urllib.parse.quote_plus(query)\n",
    "    return f\"{base}?q={q}&hl={hl}&gl={gl}&ceid={ceid}\"\n",
    "\n",
    "\n",
    "def fetch_news_items(query: str, limit: int = 5, hl: str = \"en-US\", gl: str = \"US\", ceid: str = \"US:en\") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Fetch up to `limit` items from Google News RSS for the given query.\n",
    "    Returns a list of dicts with title, link, published, summary.\n",
    "    \"\"\"\n",
    "    feed_url = google_news_rss(query, hl=hl, gl=gl, ceid=ceid)\n",
    "    parsed = feedparser.parse(feed_url)\n",
    "\n",
    "    items: List[Dict[str, Any]] = []\n",
    "    for entry in parsed.entries[:limit]:\n",
    "        items.append({\n",
    "            \"title\": entry.get(\"title\", \"\").strip(),\n",
    "            \"link\": entry.get(\"link\", \"\").strip(),\n",
    "            \"published\": entry.get(\"published\", \"\"),\n",
    "            \"summary\": entry.get(\"summary\", \"\").strip(),\n",
    "        })\n",
    "    return items\n",
    "\n",
    "\n",
    "# --------------------------- Sentiment utilities -----------------------------\n",
    "def label_from_compound(c: float) -> str:\n",
    "    \"\"\"\n",
    "    Map VADER compound score to a discrete label.\n",
    "    VADER guideline: >= 0.05 positive, <= -0.05 negative, otherwise neutral.\n",
    "    \"\"\"\n",
    "    if c >= 0.05:\n",
    "        return \"positive\"\n",
    "    elif c <= -0.05:\n",
    "        return \"negative\"\n",
    "    return \"neutral\"\n",
    "\n",
    "\n",
    "# ------------------------------- Main pipeline -------------------------------\n",
    "def analyze_news_sentiment(\n",
    "    keywords: List[str],\n",
    "    per_keyword: int = 5,\n",
    "    hl: str = \"en-US\",\n",
    "    gl: str = \"US\",\n",
    "    ceid: str = \"US:en\",\n",
    "):\n",
    "    \"\"\"\n",
    "    For each keyword:\n",
    "      - Fetch the first `per_keyword` news items from Google News RSS.\n",
    "      - Compute sentiment on (title + summary) using VADER.\n",
    "    Returns:\n",
    "      df_news: article-level DataFrame (one row per article).\n",
    "      df_summary: keyword-level summary (mean compound, class rates, count).\n",
    "    \"\"\"\n",
    "    ensure_vader()\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    rows = []\n",
    "    for kw in keywords:\n",
    "        items = fetch_news_items(kw, limit=per_keyword, hl=hl, gl=gl, ceid=ceid)\n",
    "        for it in items:\n",
    "            text = f\"{it['title']} {it['summary']}\".strip()\n",
    "            scores = sia.polarity_scores(text)\n",
    "            rows.append({\n",
    "                \"keyword\": kw,\n",
    "                \"title\": it[\"title\"],\n",
    "                \"link\": it[\"link\"],\n",
    "                \"published\": it[\"published\"],\n",
    "                \"neg\": scores[\"neg\"],\n",
    "                \"neu\": scores[\"neu\"],\n",
    "                \"pos\": scores[\"pos\"],\n",
    "                \"compound\": scores[\"compound\"],\n",
    "                \"label\": label_from_compound(scores[\"compound\"]),\n",
    "            })\n",
    "\n",
    "    df_news = pd.DataFrame(rows)\n",
    "\n",
    "    # If no articles were found for all keywords, return empty frames\n",
    "    if df_news.empty:\n",
    "        df_summary = pd.DataFrame(columns=[\"keyword\", \"mean_compound\", \"pos_rate\", \"neg_rate\", \"neu_rate\", \"n_articles\", \"label\"])\n",
    "        return df_news, df_summary\n",
    "\n",
    "    # Aggregate by keyword\n",
    "    df_summary = (\n",
    "        df_news.groupby(\"keyword\")\n",
    "               .agg(mean_compound=(\"compound\", \"mean\"),\n",
    "                    pos_rate=(\"pos\", \"mean\"),\n",
    "                    neg_rate=(\"neg\", \"mean\"),\n",
    "                    neu_rate=(\"neu\", \"mean\"),\n",
    "                    n_articles=(\"compound\", \"count\"))\n",
    "               .reset_index()\n",
    "    )\n",
    "    df_summary[\"label\"] = df_summary[\"mean_compound\"].apply(label_from_compound)\n",
    "\n",
    "    return df_news, df_summary\n",
    "\n",
    "\n",
    "# --------------------------------- Demo run ----------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Feel free to edit keywords and per_keyword\n",
    "    keywords = [\"bitcoin\", \"artificial intelligence\", \"Mexico inflation\"]\n",
    "    df_news, df_summary = analyze_news_sentiment(keywords, per_keyword=3)\n",
    "\n",
    "    # Pretty printing\n",
    "    pd.set_option(\"display.max_colwidth\", 80)\n",
    "\n",
    "    print(\"\\n=== News (article-level) ===\")\n",
    "    print(df_news)\n",
    "\n",
    "    print(\"\\n=== Summary (per keyword) ===\")\n",
    "    print(df_summary)\n",
    "\n",
    "    # Optional: export\n",
    "    # df_news.to_csv(\"news_sentiment_articles.csv\", index=False)\n",
    "    # df_summary.to_csv(\"news_sentiment_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c1327-ec11-450a-af18-d00272288205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
